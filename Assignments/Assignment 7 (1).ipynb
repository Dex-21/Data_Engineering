{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5299bba8",
   "metadata": {},
   "source": [
    "### a)Create a new Spark Session with new SparkConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6f4ff557",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6d891c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Assignment7</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=Assignment7>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "#setMaster() = Set Spark Content Manager which is local[cpu cores]\n",
    "config = SparkConf().setMaster('local[2]').setAppName(\"Assignment7\")\n",
    "sc = SparkContext(conf = config)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f03298",
   "metadata": {},
   "source": [
    "### b)Create new instance of Spark SQL session and define new DataFrame using sales_data_sample.csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e46570c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Assignment7</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f044617f550>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SQLSession').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bc9185c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = spark.read.csv(\"file:///home/hadoop/Downloads/sales_data_sample.csv\", header=True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dd6d0f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ORDERNUMBER: integer (nullable = true)\n",
      " |-- QUANTITYORDERED: integer (nullable = true)\n",
      " |-- PRICEEACH: double (nullable = true)\n",
      " |-- ORDERLINENUMBER: integer (nullable = true)\n",
      " |-- SALES: double (nullable = true)\n",
      " |-- ORDERDATE: string (nullable = true)\n",
      " |-- STATUS: string (nullable = true)\n",
      " |-- QTR_ID: integer (nullable = true)\n",
      " |-- MONTH_ID: integer (nullable = true)\n",
      " |-- YEAR_ID: integer (nullable = true)\n",
      " |-- PRODUCTLINE: string (nullable = true)\n",
      " |-- MSRP: integer (nullable = true)\n",
      " |-- PRODUCTCODE: string (nullable = true)\n",
      " |-- CUSTOMERNAME: string (nullable = true)\n",
      " |-- PHONE: string (nullable = true)\n",
      " |-- ADDRESSLINE1: string (nullable = true)\n",
      " |-- ADDRESSLINE2: string (nullable = false)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = false)\n",
      " |-- POSTALCODE: string (nullable = false)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- TERRITORY: string (nullable = true)\n",
      " |-- CONTACTLASTNAME: string (nullable = true)\n",
      " |-- CONTACTFIRSTNAME: string (nullable = true)\n",
      " |-- DEALSIZE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af007927",
   "metadata": {},
   "source": [
    "### c)Find the shape of DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c18959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2823"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7720ec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sales_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "116651e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|  SALES|      ORDERDATE| STATUS|QTR_ID|MONTH_ID|YEAR_ID|PRODUCTLINE|MSRP|PRODUCTCODE|        CUSTOMERNAME|           PHONE|        ADDRESSLINE1|ADDRESSLINE2|         CITY|   STATE|POSTALCODE|  COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+\n",
      "|      10107|             30|     95.7|              2| 2871.0| 2/24/2003 0:00|Shipped|     1|       2|   2003|Motorcycles|  95|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|            |          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|   Small|\n",
      "|      10121|             34|    81.35|              5| 2765.9|  5/7/2003 0:00|Shipped|     2|       5|   2003|Motorcycles|  95|   S10_1678|  Reims Collectables|      26.47.1555|  59 rue de l'Abbaye|            |        Reims|        |     51100|   France|     EMEA|        Henriot|            Paul|   Small|\n",
      "|      10134|             41|    94.74|              2|3884.34|  7/1/2003 0:00|Shipped|     3|       7|   2003|Motorcycles|  95|   S10_1678|     Lyon Souveniers|+33 1 46 62 7555|27 rue du Colonel...|            |        Paris|        |     75508|   France|     EMEA|       Da Cunha|          Daniel|  Medium|\n",
      "|      10145|             45|    83.26|              6| 3746.7| 8/25/2003 0:00|Shipped|     3|       8|   2003|Motorcycles|  95|   S10_1678|   Toys4GrownUps.com|      6265557265|  78934 Hillside Dr.|            |     Pasadena|      CA|     90003|      USA|       NA|          Young|           Julie|  Medium|\n",
      "|      10159|             49|    100.0|             14|5205.27|10/10/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Corporate Gift Id...|      6505551386|     7734 Strong St.|            |San Francisco|      CA|          |      USA|       NA|          Brown|           Julie|  Medium|\n",
      "|      10168|             36|    96.66|              1|3479.76|10/28/2003 0:00|Shipped|     4|      10|   2003|Motorcycles|  95|   S10_1678|Technics Stores Inc.|      6505556809|   9408 Furth Circle|            |   Burlingame|      CA|     94217|      USA|       NA|         Hirano|            Juri|  Medium|\n",
      "|      10180|             29|    86.13|              9|2497.77|11/11/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|Daedalus Designs ...|      20.16.1555|184, chausse de T...|            |        Lille|        |     59000|   France|     EMEA|          Rance|         Martine|   Small|\n",
      "|      10188|             48|    100.0|              1|5512.32|11/18/2003 0:00|Shipped|     4|      11|   2003|Motorcycles|  95|   S10_1678|        Herkku Gifts|   +47 2267 3215|Drammen 121, PR 7...|            |       Bergen|        |    N 5804|   Norway|     EMEA|         Oeztan|          Veysel|  Medium|\n",
      "|      10201|             22|    98.57|              2|2168.54| 12/1/2003 0:00|Shipped|     4|      12|   2003|Motorcycles|  95|   S10_1678|     Mini Wheels Co.|      6505555787|5557 North Pendal...|            |San Francisco|      CA|          |      USA|       NA|         Murphy|           Julie|   Small|\n",
      "|      10211|             41|    100.0|             14|4708.44| 1/15/2004 0:00|Shipped|     1|       1|   2004|Motorcycles|  95|   S10_1678|    Auto Canal Petit|  (1) 47.55.6555|   25, rue Lauriston|            |        Paris|        |     75016|   France|     EMEA|        Perrier|       Dominique|  Medium|\n",
      "|      10223|             37|    100.0|              1|3965.66| 2/20/2004 0:00|Shipped|     1|       2|   2004|Motorcycles|  95|   S10_1678|Australian Collec...|    03 9520 4555|   636 St Kilda Road|     Level 3|    Melbourne|Victoria|      3004|Australia|     APAC|       Ferguson|           Peter|  Medium|\n",
      "|      10237|             23|    100.0|              7|2333.12|  4/5/2004 0:00|Shipped|     2|       4|   2004|Motorcycles|  95|   S10_1678|     Vitachrome Inc.|      2125551500|   2678 Kingston Rd.|   Suite 101|          NYC|      NY|     10022|      USA|       NA|          Frick|         Michael|   Small|\n",
      "|      10251|             28|    100.0|              2|3188.64| 5/18/2004 0:00|Shipped|     2|       5|   2004|Motorcycles|  95|   S10_1678|Tekni Collectable...|      2015559350|       7476 Moss Rd.|            |       Newark|      NJ|     94019|      USA|       NA|          Brown|         William|  Medium|\n",
      "|      10263|             34|    100.0|              2|3676.76| 6/28/2004 0:00|Shipped|     2|       6|   2004|Motorcycles|  95|   S10_1678|     Gift Depot Inc.|      2035552570| 25593 South Bay Ln.|            |  Bridgewater|      CT|     97562|      USA|       NA|           King|           Julie|  Medium|\n",
      "|      10275|             45|    92.83|              1|4177.35| 7/23/2004 0:00|Shipped|     3|       7|   2004|Motorcycles|  95|   S10_1678|   La Rochelle Gifts|      40.67.8555|67, rue des Cinqu...|            |       Nantes|        |     44000|   France|     EMEA|        Labrune|          Janine|  Medium|\n",
      "|      10285|             36|    100.0|              6|4099.68| 8/27/2004 0:00|Shipped|     3|       8|   2004|Motorcycles|  95|   S10_1678|Marta's Replicas Co.|      6175558555| 39323 Spinnaker Dr.|            |    Cambridge|      MA|     51247|      USA|       NA|      Hernandez|           Marta|  Medium|\n",
      "|      10299|             23|    100.0|              9|2597.39| 9/30/2004 0:00|Shipped|     3|       9|   2004|Motorcycles|  95|   S10_1678|Toys of Finland, Co.|     90-224 8555|       Keskuskatu 45|            |     Helsinki|        |     21240|  Finland|     EMEA|      Karttunen|           Matti|   Small|\n",
      "|      10309|             41|    100.0|              5|4394.38|10/15/2004 0:00|Shipped|     4|      10|   2004|Motorcycles|  95|   S10_1678|  Baane Mini Imports|      07-98 9555|Erling Skakkes ga...|            |      Stavern|        |      4110|   Norway|     EMEA|     Bergulfsen|           Jonas|  Medium|\n",
      "|      10318|             46|    94.74|              1|4358.04| 11/2/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|  95|   S10_1678|Diecast Classics ...|      2155551555|    7586 Pompton St.|            |    Allentown|      PA|     70267|      USA|       NA|             Yu|           Kyung|  Medium|\n",
      "|      10329|             42|    100.0|              1|4396.14|11/15/2004 0:00|Shipped|     4|      11|   2004|Motorcycles|  95|   S10_1678|   Land of Toys Inc.|      2125557818|897 Long Airport ...|            |          NYC|      NY|     10022|      USA|       NA|             Yu|            Kwai|  Medium|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+-----------+----+-----------+--------------------+----------------+--------------------+------------+-------------+--------+----------+---------+---------+---------------+----------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b7c4b",
   "metadata": {},
   "source": [
    "### d) Find the Summary of DataFrame for all numerical data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc10c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORDERNUMBER',\n",
       " 'QUANTITYORDERED',\n",
       " 'PRICEEACH',\n",
       " 'ORDERLINENUMBER',\n",
       " 'SALES',\n",
       " 'QTR_ID',\n",
       " 'MONTH_ID',\n",
       " 'YEAR_ID',\n",
       " 'MSRP']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "num_cols = [field.name for field in sales_df.schema.fields if isinstance(field.dataType, (IntegerType,FloatType, LongType, DoubleType, DecimalType))]\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd07cd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|       ORDERNUMBER|  QUANTITYORDERED|         PRICEEACH|  ORDERLINENUMBER|             SALES|            QTR_ID|          MONTH_ID|           YEAR_ID|              MSRP|\n",
      "+-------+------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|              2823|             2823|              2823|             2823|              2823|              2823|              2823|              2823|              2823|\n",
      "|   mean|10258.725115125753|35.09280906836698| 83.65854410201929|6.466170740347148|  3553.88907190932|2.7176762309599716|7.0924548352816155|2003.8150903294368|100.71555083244775|\n",
      "| stddev|  92.0854775957196| 9.74144273706958|20.174276527840536| 4.22584096469094|1841.8651057401842| 1.203878088001756| 3.656633307661765|0.6996701541300869| 40.18791167720266|\n",
      "|    min|             10100|                6|             26.88|                1|            482.13|                 1|                 1|              2003|                33|\n",
      "|    max|             10425|               97|             100.0|               18|           14082.8|                 4|                12|              2005|               214|\n",
      "+-------+------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.describe(num_cols).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766e39d",
   "metadata": {},
   "source": [
    "### e)Identify and handle missing or null values in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d0b34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbee2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORDERNUMBER': 0}\n",
      "{'QUANTITYORDERED': 0}\n",
      "{'PRICEEACH': 0}\n",
      "{'ORDERLINENUMBER': 0}\n",
      "{'SALES': 0}\n",
      "{'ORDERDATE': 0}\n",
      "{'STATUS': 0}\n",
      "{'QTR_ID': 0}\n",
      "{'MONTH_ID': 0}\n",
      "{'YEAR_ID': 0}\n",
      "{'PRODUCTLINE': 0}\n",
      "{'MSRP': 0}\n",
      "{'PRODUCTCODE': 0}\n",
      "{'CUSTOMERNAME': 0}\n",
      "{'PHONE': 0}\n",
      "{'ADDRESSLINE1': 0}\n",
      "{'ADDRESSLINE2': 2521}\n",
      "{'CITY': 0}\n",
      "{'STATE': 1486}\n",
      "{'POSTALCODE': 76}\n",
      "{'COUNTRY': 0}\n",
      "{'TERRITORY': 0}\n",
      "{'CONTACTLASTNAME': 0}\n",
      "{'CONTACTFIRSTNAME': 0}\n",
      "{'DEALSIZE': 0}\n"
     ]
    }
   ],
   "source": [
    "for columns in sales_df.columns:\n",
    "    print({columns:sales_df.filter(col(columns).isNull()).count()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4804e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df.fillna({'ADDRESSLINE2': \"\", 'STATE':\"\", 'POSTALCODE': \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bab81a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORDERNUMBER': 0}\n",
      "{'QUANTITYORDERED': 0}\n",
      "{'PRICEEACH': 0}\n",
      "{'ORDERLINENUMBER': 0}\n",
      "{'SALES': 0}\n",
      "{'ORDERDATE': 0}\n",
      "{'STATUS': 0}\n",
      "{'QTR_ID': 0}\n",
      "{'MONTH_ID': 0}\n",
      "{'YEAR_ID': 0}\n",
      "{'PRODUCTLINE': 0}\n",
      "{'MSRP': 0}\n",
      "{'PRODUCTCODE': 0}\n",
      "{'CUSTOMERNAME': 0}\n",
      "{'PHONE': 0}\n",
      "{'ADDRESSLINE1': 0}\n",
      "{'ADDRESSLINE2': 0}\n",
      "{'CITY': 0}\n",
      "{'STATE': 0}\n",
      "{'POSTALCODE': 0}\n",
      "{'COUNTRY': 0}\n",
      "{'TERRITORY': 0}\n",
      "{'CONTACTLASTNAME': 0}\n",
      "{'CONTACTFIRSTNAME': 0}\n",
      "{'DEALSIZE': 0}\n"
     ]
    }
   ],
   "source": [
    "for columns in sales_df.columns:\n",
    "    print({columns:sales_df.filter(col(columns).isNull()).count()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd8768",
   "metadata": {},
   "source": [
    "### f) Calculate the total revenue generated per country by combining the columns QUANTITYORDERED and PRICEEACH using Spark DataFrame operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8f2180c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df1 = sales_df.withColumn(\"REVENUE\",\n",
    "                                 col(\"QUANTITYORDERED\") * col(\"PRICEEACH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3dc613c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df2 = sales_df1.groupBy(\"COUNTRY\").agg(sum(\"REVENUE\").alias(\"TOTAL_REVENUE\")).orderBy(desc(\"TOTAL_REVENUE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fe648475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|    COUNTRY|     TOTAL_REVENUE|\n",
      "+-----------+------------------+\n",
      "|        USA|2986425.2099999995|\n",
      "|      Spain|1021705.9700000002|\n",
      "|     France| 919257.8499999997|\n",
      "|  Australia|521598.45999999985|\n",
      "|         UK|413203.33999999997|\n",
      "|      Italy| 309402.8699999999|\n",
      "|    Finland|268714.70000000007|\n",
      "|     Norway| 246115.8000000001|\n",
      "|  Singapore| 227985.5000000001|\n",
      "|     Canada|193504.34000000003|\n",
      "|    Denmark|         192747.63|\n",
      "|    Germany|         178689.08|\n",
      "|     Sweden|174264.10000000006|\n",
      "|    Austria|172793.05000000002|\n",
      "|      Japan|153076.68999999994|\n",
      "|    Belgium|          94528.88|\n",
      "|Switzerland| 93344.90999999999|\n",
      "|Philippines| 80291.16999999998|\n",
      "|    Ireland|          43237.24|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4aa200",
   "metadata": {},
   "source": [
    "### g) Determine the top 5 products with the highest total sales revenue using Spark DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d748a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-------+\n",
      "| PRODUCTLINE|PRODUCTCODE|REVENUE|\n",
      "+------------+-----------+-------+\n",
      "|Classic Cars|   S12_4675|9048.16|\n",
      "|Vintage Cars|   S18_1749| 7600.0|\n",
      "|Classic Cars|   S24_3856| 7600.0|\n",
      "|      Planes|  S700_2466|7543.75|\n",
      "|Classic Cars|   S24_2766| 7182.0|\n",
      "+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df3 = sales_df1.orderBy(col('REVENUE').desc())\n",
    "sales_df3.select(['PRODUCTLINE','PRODUCTCODE','REVENUE']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ef042",
   "metadata": {},
   "source": [
    "### h) Find the average order quantity for each product using groupBy and agg operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f661fa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|PRODUCTCODE|      AVG_QUANTITY|\n",
      "+-----------+------------------+\n",
      "|   S18_4600| 38.18518518518518|\n",
      "|   S18_1749| 36.45454545454545|\n",
      "|   S12_3891| 35.42307692307692|\n",
      "|   S18_2248| 33.77272727272727|\n",
      "|  S700_1138| 34.69230769230769|\n",
      "|   S32_1268|32.333333333333336|\n",
      "|   S12_1099|             33.52|\n",
      "|   S18_2795|30.346153846153847|\n",
      "|   S24_1937|             33.76|\n",
      "|   S32_3522| 35.44444444444444|\n",
      "|   S18_1097| 35.67857142857143|\n",
      "|   S18_1662| 36.15384615384615|\n",
      "|   S12_1666|34.714285714285715|\n",
      "|   S24_3969| 33.86363636363637|\n",
      "|   S24_1578| 35.80769230769231|\n",
      "|   S24_4048| 32.46153846153846|\n",
      "|   S18_3320| 34.96153846153846|\n",
      "|   S24_3816| 33.46153846153846|\n",
      "|   S18_3136|32.333333333333336|\n",
      "|   S32_2509|34.107142857142854|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df1.groupBy(\"PRODUCTCODE\").agg(avg(\"QUANTITYORDERED\").alias(\"AVG_QUANTITY\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f62c25",
   "metadata": {},
   "source": [
    "### i) Using Spark DataFrame, filter orders where the SALES value exceeds 10,000 and sort theresults by the ORDERDATE column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a742c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df1 = sales_df1.withColumn(\"ORDERDATE\", to_date(col(\"ORDERDATE\"), \"M/d/yyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c7108ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+\n",
      "|ORDERNUMBER|  SALES| ORDERDATE|\n",
      "+-----------+-------+----------+\n",
      "|      10127|11279.2|2003-06-03|\n",
      "|      10150|10993.5|2003-09-19|\n",
      "|      10247|10606.2|2004-05-05|\n",
      "|      10304|10172.7|2004-10-11|\n",
      "|      10312|11623.7|2004-10-21|\n",
      "|      10322|12536.5|2004-11-04|\n",
      "|      10333|11336.7|2004-11-18|\n",
      "|      10339|10758.0|2004-11-23|\n",
      "|      10375|10039.6|2005-02-03|\n",
      "|      10388|10066.6|2005-03-03|\n",
      "|      10403|11886.6|2005-04-08|\n",
      "|      10405|11739.7|2005-04-14|\n",
      "|      10406|10468.9|2005-04-15|\n",
      "|      10407|14082.8|2005-04-22|\n",
      "|      10412|11887.8|2005-05-03|\n",
      "|      10424|12001.0|2005-05-31|\n",
      "+-----------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df = sales_df1.filter(col(\"SALES\") > 10000).orderBy(col('ORDERDATE'))\n",
    "filtered_df.select(['ORDERNUMBER','SALES','ORDERDATE']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea0970",
   "metadata": {},
   "source": [
    "### j) Filter out rows where the STATUS is &#39;Cancelled&#39; and calculate the total sales from the remaining orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e58211a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      total_sales|\n",
      "+-----------------+\n",
      "|9838141.370000018|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cancelled_df = sales_df1.filter(col('STATUS') != 'Cancelled')\n",
    "total_sales = cancelled_df.agg(sum(col('SALES')).alias('total_sales'))\n",
    "total_sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512f896",
   "metadata": {},
   "source": [
    "### k) Use Spark Data Frame transformations to derive the yearly sales for each customer (CUSTOMERNAME) based on the ORDERDATE column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90b5c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df2 = sales_df1.withColumn('ORDER_YEAR', year(col('ORDERDATE')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1959bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_sales = (sales_df2.groupBy(\"CUSTOMERNAME\",\"ORDER_YEAR\")\n",
    "                .agg(sum(col('SALES')).alias('yearly_sales')).orderBy(\"CUSTOMERNAME\",\"ORDER_YEAR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e30eeae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+\n",
      "|        CUSTOMERNAME|ORDER_YEAR|      yearly_sales|\n",
      "+--------------------+----------+------------------+\n",
      "|      AV Stores, Co.|      2003| 51017.91999999999|\n",
      "|      AV Stores, Co.|      2004|         106789.89|\n",
      "|        Alpha Cognac|      2003| 55349.31999999999|\n",
      "|        Alpha Cognac|      2005|15139.119999999999|\n",
      "|  Amica Models & Co.|      2004| 94117.26000000002|\n",
      "|Anna's Decoration...|      2003| 88983.70999999999|\n",
      "|Anna's Decoration...|      2005|          65012.42|\n",
      "|   Atelier graphique|      2003|           16560.3|\n",
      "|   Atelier graphique|      2004|           7619.66|\n",
      "|Australian Collec...|      2003|          37878.55|\n",
      "+--------------------+----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yearly_sales.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b097b",
   "metadata": {},
   "source": [
    "### l) Add a new column to the DataFrame that categorizes orders as\"High\", \"Medium\" or \"Low\" sales based on the SALES value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09357b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+\n",
      "|  SALES|        CUSTOMERNAME|SALES_CATEGORY|\n",
      "+-------+--------------------+--------------+\n",
      "| 2871.0|   Land of Toys Inc.|           Low|\n",
      "| 2765.9|  Reims Collectables|           Low|\n",
      "|3884.34|     Lyon Souveniers|        Medium|\n",
      "| 3746.7|   Toys4GrownUps.com|        Medium|\n",
      "|5205.27|Corporate Gift Id...|        Medium|\n",
      "|3479.76|Technics Stores Inc.|        Medium|\n",
      "|2497.77|Daedalus Designs ...|           Low|\n",
      "|5512.32|        Herkku Gifts|        Medium|\n",
      "|2168.54|     Mini Wheels Co.|           Low|\n",
      "|4708.44|    Auto Canal Petit|        Medium|\n",
      "|3965.66|Australian Collec...|        Medium|\n",
      "|2333.12|     Vitachrome Inc.|           Low|\n",
      "|3188.64|Tekni Collectable...|        Medium|\n",
      "|3676.76|     Gift Depot Inc.|        Medium|\n",
      "|4177.35|   La Rochelle Gifts|        Medium|\n",
      "|4099.68|Marta's Replicas Co.|        Medium|\n",
      "|2597.39|Toys of Finland, Co.|           Low|\n",
      "|4394.38|  Baane Mini Imports|        Medium|\n",
      "|4358.04|Diecast Classics ...|        Medium|\n",
      "|4396.14|   Land of Toys Inc.|        Medium|\n",
      "|7737.93|Salzburg Collecta...|        Medium|\n",
      "| 1451.0|Souveniers And Th...|           Low|\n",
      "| 733.11|   La Rochelle Gifts|           Low|\n",
      "|3207.12|    FunGiftIdeas.com|        Medium|\n",
      "|2434.56|UK Collectables, ...|           Low|\n",
      "|7516.08|Euro Shopping Cha...|        Medium|\n",
      "|5404.62|  Baane Mini Imports|        Medium|\n",
      "|7209.11|Volvo Model Repli...|        Medium|\n",
      "|7329.06|Corrida Auto Repl...|        Medium|\n",
      "| 7374.1|Technics Stores Inc.|        Medium|\n",
      "+-------+--------------------+--------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df4 = sales_df1.withColumn(\n",
    "    'SALES_CATEGORY',\n",
    "    when(col('SALES') > 8000, 'High')\n",
    "    .when(col('SALES') > 3000, 'Medium')\n",
    "    .otherwise('Low')\n",
    ")\n",
    "sales_df4.select(['SALES','CUSTOMERNAME','SALES_CATEGORY']).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f67700",
   "metadata": {},
   "source": [
    "### m) Assume, If you have another DataFrame with customer demographic data, how would you perform a join to compute the total sales per demographic group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "564a76f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|        CUSTOMERNAME|DEMOGRAPHIC_GROUP|\n",
      "+--------------------+-----------------+\n",
      "|   Land of Toys Inc.|           Retail|\n",
      "|  Reims Collectables|           Retail|\n",
      "|     Lyon Souveniers|           Retail|\n",
      "|   Toys4GrownUps.com|        Wholesale|\n",
      "|Corporate Gift Ideas|        Wholesale|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (\"Land of Toys Inc.\", \"Retail\"),\n",
    "    (\"Reims Collectables\", \"Retail\"),\n",
    "    (\"Lyon Souveniers\", \"Retail\"),\n",
    "    (\"Toys4GrownUps.com\", \"Wholesale\"),\n",
    "    (\"Corporate Gift Ideas\", \"Wholesale\")]\n",
    "columns = [\"CUSTOMERNAME\", \"DEMOGRAPHIC_GROUP\"]\n",
    "demographic_df = spark.createDataFrame(data,columns)\n",
    "demographic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "898e7ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|DEMOGRAPHIC_GROUP|       TOTAL_SALES|\n",
      "+-----------------+------------------+\n",
      "|        Wholesale|104561.95999999998|\n",
      "|           Retail|         377682.72|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_df = sales_df1.join(demographic_df, on='CUSTOMERNAME', how='inner')\n",
    "sales_demographic = join_df.groupBy('DEMOGRAPHIC_GROUP').agg(sum('SALES').alias('TOTAL_SALES'))\n",
    "sales_demographic.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e321aa",
   "metadata": {},
   "source": [
    "### n) Can you implement a cumulative distribution function (CDF) over the SALES value for each CUSTOMERNAME? What insights can you gather from analyzing the CDF distribution for each customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d37a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fcbeb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_df = Window.partitionBy('CUSTOMERNAME').orderBy('SALES')\n",
    "ranked_df = sales_df1.withColumn('RANK', row_number().over(window_df))\n",
    "total_sales = sales_df1.groupBy('CUSTOMERNAME').agg(count('SALES').alias('TOTAL_COUNT'))\n",
    "sales_new = ranked_df.join(total_sales, on='CUSTOMERNAME')\n",
    "sales_cdf = sales_new.withColumn('CDF', col('RANK') / col('TOTAL_COUNT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1229ffef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----+-----------+--------------------+\n",
      "|        CUSTOMERNAME|  SALES|RANK|TOTAL_COUNT|                 CDF|\n",
      "+--------------------+-------+----+-----------+--------------------+\n",
      "| Suominen Souveniers| 891.03|   1|         30| 0.03333333333333333|\n",
      "| Suominen Souveniers| 1086.6|   2|         30| 0.06666666666666667|\n",
      "| Suominen Souveniers|1103.76|   3|         30|                 0.1|\n",
      "| Suominen Souveniers|1629.04|   4|         30| 0.13333333333333333|\n",
      "| Suominen Souveniers| 1988.4|   5|         30| 0.16666666666666666|\n",
      "| Suominen Souveniers|2140.11|   6|         30|                 0.2|\n",
      "| Suominen Souveniers|2447.76|   7|         30| 0.23333333333333334|\n",
      "| Suominen Souveniers|2632.89|   8|         30| 0.26666666666666666|\n",
      "| Suominen Souveniers| 2773.8|   9|         30|                 0.3|\n",
      "| Suominen Souveniers|2775.08|  10|         30|  0.3333333333333333|\n",
      "| Suominen Souveniers|2817.87|  11|         30| 0.36666666666666664|\n",
      "| Suominen Souveniers|2851.84|  12|         30|                 0.4|\n",
      "| Suominen Souveniers|2931.98|  13|         30| 0.43333333333333335|\n",
      "| Suominen Souveniers|3128.65|  14|         30|  0.4666666666666667|\n",
      "| Suominen Souveniers|3288.82|  15|         30|                 0.5|\n",
      "| Suominen Souveniers|3595.62|  16|         30|  0.5333333333333333|\n",
      "| Suominen Souveniers|3686.54|  17|         30|  0.5666666666666667|\n",
      "| Suominen Souveniers| 3784.8|  18|         30|                 0.6|\n",
      "| Suominen Souveniers| 4068.7|  19|         30|  0.6333333333333333|\n",
      "| Suominen Souveniers|4142.64|  20|         30|  0.6666666666666666|\n",
      "| Suominen Souveniers|4157.73|  21|         30|                 0.7|\n",
      "| Suominen Souveniers|4381.25|  22|         30|  0.7333333333333333|\n",
      "| Suominen Souveniers| 4836.5|  23|         30|  0.7666666666666667|\n",
      "| Suominen Souveniers|5154.41|  24|         30|                 0.8|\n",
      "| Suominen Souveniers|5500.44|  25|         30|  0.8333333333333334|\n",
      "| Suominen Souveniers|5938.53|  26|         30|  0.8666666666666667|\n",
      "| Suominen Souveniers|6287.66|  27|         30|                 0.9|\n",
      "| Suominen Souveniers| 6576.5|  28|         30|  0.9333333333333333|\n",
      "| Suominen Souveniers| 6756.0|  29|         30|  0.9666666666666667|\n",
      "| Suominen Souveniers|10606.2|  30|         30|                 1.0|\n",
      "|  Amica Models & Co.|  577.6|   1|         26|0.038461538461538464|\n",
      "|  Amica Models & Co.|1381.05|   2|         26| 0.07692307692307693|\n",
      "|  Amica Models & Co.|1557.36|   3|         26| 0.11538461538461539|\n",
      "|  Amica Models & Co.| 1574.0|   4|         26| 0.15384615384615385|\n",
      "|  Amica Models & Co.|1656.69|   5|         26| 0.19230769230769232|\n",
      "|  Amica Models & Co.|1921.92|   6|         26| 0.23076923076923078|\n",
      "|  Amica Models & Co.|2084.81|   7|         26|  0.2692307692307692|\n",
      "|  Amica Models & Co.|2137.05|   8|         26|  0.3076923076923077|\n",
      "|  Amica Models & Co.|2418.24|   9|         26| 0.34615384615384615|\n",
      "|  Amica Models & Co.|2800.08|  10|         26| 0.38461538461538464|\n",
      "|  Amica Models & Co.|2819.28|  11|         26|  0.4230769230769231|\n",
      "|  Amica Models & Co.|2941.89|  12|         26| 0.46153846153846156|\n",
      "|  Amica Models & Co.|2954.53|  13|         26|                 0.5|\n",
      "|  Amica Models & Co.|3006.43|  14|         26|  0.5384615384615384|\n",
      "|  Amica Models & Co.|3474.46|  15|         26|  0.5769230769230769|\n",
      "|  Amica Models & Co.| 3668.6|  16|         26|  0.6153846153846154|\n",
      "|  Amica Models & Co.|3704.05|  17|         26|  0.6538461538461539|\n",
      "|  Amica Models & Co.|4242.24|  18|         26|  0.6923076923076923|\n",
      "|  Amica Models & Co.| 4455.0|  19|         26|  0.7307692307692307|\n",
      "|  Amica Models & Co.| 4750.8|  20|         26|  0.7692307692307693|\n",
      "|  Amica Models & Co.|4946.06|  21|         26|  0.8076923076923077|\n",
      "|  Amica Models & Co.|5126.24|  22|         26|  0.8461538461538461|\n",
      "|  Amica Models & Co.| 5239.5|  23|         26|  0.8846153846153846|\n",
      "|  Amica Models & Co.|8014.82|  24|         26|  0.9230769230769231|\n",
      "|  Amica Models & Co.| 8253.0|  25|         26|  0.9615384615384616|\n",
      "|  Amica Models & Co.|8411.56|  26|         26|                 1.0|\n",
      "|Collectables For ...|1066.75|   1|         24|0.041666666666666664|\n",
      "|Collectables For ...|1237.88|   2|         24| 0.08333333333333333|\n",
      "|Collectables For ...|1340.64|   3|         24|               0.125|\n",
      "|Collectables For ...|1735.92|   4|         24| 0.16666666666666666|\n",
      "+--------------------+-------+----+-----------+--------------------+\n",
      "only showing top 60 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_cdf.select('CUSTOMERNAME', 'SALES', 'RANK','TOTAL_COUNT','CDF').show(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815fb32e",
   "metadata": {},
   "source": [
    "Insight : Higher sales values correspond to higher CDF values. This shows a non-decreasing trend as sales increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afca327",
   "metadata": {},
   "source": [
    "### o) Write spark dataframe code to rank products by total revenue within each country (COUNTRY)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0670a451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----------------+------------------+----+\n",
      "|COUNTRY|PRODUCTCODE|     PRODUCTLINE|     TOTAL_REVENUE|RANK|\n",
      "+-------+-----------+----------------+------------------+----+\n",
      "| Sweden|   S10_1949|    Classic Cars|           14345.3|   1|\n",
      "| Sweden|   S18_4600|Trucks and Buses|          12052.11|   2|\n",
      "| Sweden|   S24_2300|Trucks and Buses|10926.119999999999|   3|\n",
      "| Sweden|   S12_1099|    Classic Cars|           9451.15|   4|\n",
      "| Sweden|   S18_2949|    Vintage Cars|           8253.68|   5|\n",
      "| Sweden|   S24_2011|           Ships|           8145.45|   6|\n",
      "| Sweden|   S10_4962|    Classic Cars|           7044.02|   7|\n",
      "| Sweden|   S18_2625|     Motorcycles|            6981.0|   8|\n",
      "| Sweden|   S12_3380|    Classic Cars|            6659.8|   9|\n",
      "| Sweden|   S12_1666|Trucks and Buses|            6387.8|  10|\n",
      "| Sweden|   S10_4757|    Classic Cars|           5924.16|  11|\n",
      "| Sweden|   S18_2319|Trucks and Buses|           5814.86|  12|\n",
      "| Sweden|   S18_1662|          Planes|           5763.72|  13|\n",
      "| Sweden|  S700_1138|           Ships|           5579.62|  14|\n",
      "| Sweden|   S12_3990|    Classic Cars|           5319.32|  15|\n",
      "| Sweden|   S12_4675|    Classic Cars|           5243.79|  16|\n",
      "| Sweden|   S24_3151|    Vintage Cars|           5113.05|  17|\n",
      "| Sweden|   S18_1097|Trucks and Buses|           4687.94|  18|\n",
      "| Sweden|   S24_1578|     Motorcycles|           4597.65|  19|\n",
      "| Sweden|   S18_4522|    Vintage Cars|            4300.5|  20|\n",
      "| Sweden|   S24_3816|    Vintage Cars|4276.9400000000005|  21|\n",
      "| Sweden|   S24_2000|     Motorcycles|            3988.6|  22|\n",
      "| Sweden|   S18_1889|    Classic Cars|           3881.78|  23|\n",
      "| Sweden|   S18_3259|          Trains|           3807.68|  24|\n",
      "| Sweden|   S18_3856|    Vintage Cars|           3599.58|  25|\n",
      "| Sweden|   S18_2432|Trucks and Buses|            3587.9|  26|\n",
      "| Sweden|   S18_3482|    Classic Cars|            3491.0|  27|\n",
      "| Sweden|   S18_3029|           Ships|           3363.52|  28|\n",
      "| Sweden|  S700_2824|    Classic Cars|           3256.96|  29|\n",
      "| Sweden|  S700_2610|           Ships|           3225.06|  30|\n",
      "| Sweden|  S700_3962|           Ships|            3003.0|  31|\n",
      "| Sweden|  S700_2047|           Ships|           2940.02|  32|\n",
      "| Sweden|   S18_3232|    Classic Cars|            2878.8|  33|\n",
      "| Sweden|   S18_3136|    Vintage Cars|           2866.26|  34|\n",
      "| Sweden|  S700_3505|           Ships|            2812.8|  35|\n",
      "| Sweden|   S32_3522|Trucks and Buses|            2296.0|  36|\n",
      "| Sweden|   S32_1268|Trucks and Buses|           2178.54|  37|\n",
      "| Sweden|   S24_3420|    Vintage Cars|           2019.84|  38|\n",
      "| Sweden|   S18_2957|    Vintage Cars|           1871.83|  39|\n",
      "| Sweden|   S72_3212|           Ships|           1846.42|  40|\n",
      "+-------+-----------+----------------+------------------+----+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "revenue_df = sales_df1.groupBy('COUNTRY', 'PRODUCTCODE','PRODUCTLINE') \\\n",
    "    .agg(sum('SALES').alias('TOTAL_REVENUE'))\n",
    "new_df = Window.partitionBy('COUNTRY').orderBy(col('TOTAL_REVENUE').desc())\n",
    "ranked_df = revenue_df.withColumn('RANK', rank().over(new_df))\n",
    "ranked_df.show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0dc2b",
   "metadata": {},
   "source": [
    "Insight : In Sweden , Classic Cars has the highest sales revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a576479a",
   "metadata": {},
   "source": [
    "### p) Calculate a running total of SALES for each customer and show the top 5 customers by this cumulative total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b59b13e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------+\n",
      "|        CUSTOMERNAME|TOTAL_SALES|CUMULATIVE_SUM|\n",
      "+--------------------+-----------+--------------+\n",
      "|Euro Shopping Cha...|  912294.11| 1.003262885E7|\n",
      "|Mini Gifts Distri...|  654858.06|    9120334.74|\n",
      "|Australian Collec...|  200995.41|    8465476.68|\n",
      "|  Muscle Machine Inc|  197736.94|    8264481.27|\n",
      "|   La Rochelle Gifts|   180124.9|    8066744.33|\n",
      "+--------------------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cumulative = Window.orderBy('TOTAL_SALES').rowsBetween(Window.unboundedPreceding,Window.currentRow)\n",
    "total_df = (sales_df1.select('CUSTOMERNAME','SALES').groupBy('CUSTOMERNAME')\n",
    "         .agg(round(sum('SALES'),2).alias('TOTAL_SALES')))\n",
    "total_df = total_df.withColumn('CUMULATIVE_SUM',round(sum('TOTAL_SALES').over(cumulative),2))\n",
    "total_df.orderBy('CUMULATIVE_SUM',ascending=False).limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2466f14",
   "metadata": {},
   "source": [
    "### q) Find and handle Invalid and Outliers values in entire DataFrame. [Check for only continuous dataset]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "75ca87a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------+---------------+-------+----------+-------+------+--------+-------+-----------+----+-----------+------------------+----------------+--------------------+------------+--------+-----+----------+-------+---------+---------------+----------------+--------+------------------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|  SALES| ORDERDATE| STATUS|QTR_ID|MONTH_ID|YEAR_ID|PRODUCTLINE|MSRP|PRODUCTCODE|      CUSTOMERNAME|           PHONE|        ADDRESSLINE1|ADDRESSLINE2|    CITY|STATE|POSTALCODE|COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|           REVENUE|\n",
      "+-----------+---------------+---------+---------------+-------+----------+-------+------+--------+-------+-----------+----+-----------+------------------+----------------+--------------------+------------+--------+-----+----------+-------+---------+---------------+----------------+--------+------------------+\n",
      "|      10107|             30|     95.7|              2| 2871.0|2003-02-24|Shipped|     1|       2|   2003|Motorcycles|  95|   S10_1678| Land of Toys Inc.|      2125557818|897 Long Airport ...|            |     NYC|   NY|     10022|    USA|       NA|             Yu|            Kwai|   Small|            2871.0|\n",
      "|      10121|             34|    81.35|              5| 2765.9|2003-05-07|Shipped|     2|       5|   2003|Motorcycles|  95|   S10_1678|Reims Collectables|      26.47.1555|  59 rue de l'Abbaye|            |   Reims|     |     51100| France|     EMEA|        Henriot|            Paul|   Small|2765.8999999999996|\n",
      "|      10134|             41|    94.74|              2|3884.34|2003-07-01|Shipped|     3|       7|   2003|Motorcycles|  95|   S10_1678|   Lyon Souveniers|+33 1 46 62 7555|27 rue du Colonel...|            |   Paris|     |     75508| France|     EMEA|       Da Cunha|          Daniel|  Medium|3884.3399999999997|\n",
      "|      10145|             45|    83.26|              6| 3746.7|2003-08-25|Shipped|     3|       8|   2003|Motorcycles|  95|   S10_1678| Toys4GrownUps.com|      6265557265|  78934 Hillside Dr.|            |Pasadena|   CA|     90003|    USA|       NA|          Young|           Julie|  Medium|3746.7000000000003|\n",
      "+-----------+---------------+---------+---------------+-------+----------+-------+------+--------+-------+-----------+----+-----------+------------------+----------------+--------------------+------------+--------+-----+----------+-------+---------+---------------+----------------+--------+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_iqr(sales_df1, column_name):\n",
    "    q1 = sales_df1.approxQuantile(column_name, [0.25], 0.001)[0]\n",
    "    q3 = sales_df1.approxQuantile(column_name, [0.75], 0.001)[0]\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    new_sales = sales_df1.filter((col(column_name) >= lower_bound) & \n",
    "                                 (col(column_name) <= upper_bound))\n",
    "    return new_sales.withColumn(column_name,when(col(column_name) < lower_bound, lower_bound)\n",
    "        .when(col(column_name) > upper_bound, upper_bound).otherwise(col(column_name)))\n",
    "\n",
    "handled_df = calculate_iqr(sales_df1, \"SALES\")\n",
    "handled_df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a6150",
   "metadata": {},
   "source": [
    "### r) How would you cache a DataFrame containing sales data from the top 10 countries by sales to avoid recomputation in subsequent transformations? What persistence level (e.g. MEMORY_ONLY, MEMORY_AND_DISK) would you choose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cbf72786",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "country_df = sales_df1.groupBy('COUNTRY') \\\n",
    "    .agg(sum('SALES').alias('TOTAL_SALES')) \\\n",
    "    .orderBy(desc('TOTAL_SALES')).limit(10)\n",
    "\n",
    "top_countries = [row['COUNTRY'] for row in country_df.collect()]\n",
    "top_sales = sales_df1.filter(col('COUNTRY').isin(top_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7cff8340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ORDERNUMBER: int, QUANTITYORDERED: int, PRICEEACH: double, ORDERLINENUMBER: int, SALES: double, ORDERDATE: date, STATUS: string, QTR_ID: int, MONTH_ID: int, YEAR_ID: int, PRODUCTLINE: string, MSRP: int, PRODUCTCODE: string, CUSTOMERNAME: string, PHONE: string, ADDRESSLINE1: string, ADDRESSLINE2: string, CITY: string, STATE: string, POSTALCODE: string, COUNTRY: string, TERRITORY: string, CONTACTLASTNAME: string, CONTACTFIRSTNAME: string, DEALSIZE: string, REVENUE: double]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sales.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0259783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ORDERNUMBER: int, QUANTITYORDERED: int, PRICEEACH: double, ORDERLINENUMBER: int, SALES: double, ORDERDATE: date, STATUS: string, QTR_ID: int, MONTH_ID: int, YEAR_ID: int, PRODUCTLINE: string, MSRP: int, PRODUCTCODE: string, CUSTOMERNAME: string, PHONE: string, ADDRESSLINE1: string, ADDRESSLINE2: string, CITY: string, STATE: string, POSTALCODE: string, COUNTRY: string, TERRITORY: string, CONTACTLASTNAME: string, CONTACTFIRSTNAME: string, DEALSIZE: string, REVENUE: double]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sales.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fad79",
   "metadata": {},
   "source": [
    "Choosed memory only persistence level because the dataset can be fitted in the memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce454198",
   "metadata": {},
   "source": [
    "### s) How would you pivot the data to show PRODUCTLINE as columns and the total SALES for each ORDERDATE as the values? What are the implications of pivoting large datasets in Spark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4eafc1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+-------+--------+----------------+------------------+\n",
      "| ORDERDATE|      Classic Cars|       Motorcycles|            Planes|  Ships|  Trains|Trucks and Buses|      Vintage Cars|\n",
      "+----------+------------------+------------------+------------------+-------+--------+----------------+------------------+\n",
      "|2003-11-11|           7557.04|41317.240000000005|              null|   null|    null|            null|              null|\n",
      "|2003-07-16|              null|              null|              null|   null|    null|            null|28397.260000000002|\n",
      "|2004-11-01|          14094.32|              null|          24409.53|9756.42|    null|        15508.35|22112.140000000003|\n",
      "|2004-11-05|          40174.03|              null|              null|   null|11310.36|         36985.8|           17770.5|\n",
      "|2003-10-11|          24159.14|              null|              null|   null|    null|            null|              null|\n",
      "|2004-05-04|          15340.86|              null|              null|   null|    null|         18938.3|           2694.15|\n",
      "|2004-12-03|              null|              null|16942.719999999998|2352.67|    null|            null|           5973.04|\n",
      "|2005-02-23|            4846.7|              null|              null|8652.56|    null|            null|           4208.41|\n",
      "|2003-05-07|              null|          18971.96|              null|   null|    null|            null|              null|\n",
      "|2003-11-06|60258.270000000004|              null|              null|   null| 3856.72|        42555.42|7786.4400000000005|\n",
      "+----------+------------------+------------------+------------------+-------+--------+----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivot_df = sales_df1.groupBy('ORDERDATE').pivot('PRODUCTLINE').agg(sum('SALES'))\n",
    "pivot_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a64279",
   "metadata": {},
   "source": [
    "* Pivoting large datasets can lead to high memory usage. \n",
    "* Pivoted DataFrames with a high number of columns can become difficult to manage and analyze. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1d9c4",
   "metadata": {},
   "source": [
    "### t) How would you calculate the percentage growth of total sales month over month for each PRODUCTLINE using Spark DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5a04bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df2 = sales_df1.withColumn('ORDER_MONTH', month(col('ORDERDATE')))\n",
    "sales_df2 = sales_df2.withColumn('ORDER_YEAR', year(col('ORDERDATE')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eb2f1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_sales = sales_df2.groupBy('ORDER_YEAR', 'ORDER_MONTH', 'PRODUCTLINE') \\\n",
    "    .agg(sum('SALES').alias('TOTAL_SALES')).orderBy(desc('TOTAL_SALES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "95b52a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------+------------------+------------------+-------------------+\n",
      "|ORDER_YEAR|ORDER_MONTH|PRODUCTLINE|       TOTAL_SALES|  PREV_TOTAL_SALES|  PERCENTAGE_GROWTH|\n",
      "+----------+-----------+-----------+------------------+------------------+-------------------+\n",
      "|      2003|          2|Motorcycles|25783.760000000002|              null|               null|\n",
      "|      2003|          3|Motorcycles|          12639.15|25783.760000000002| -50.98019063162239|\n",
      "|      2003|          4|Motorcycles|23475.590000000004|          12639.15|   85.7370946622202|\n",
      "|      2003|          5|Motorcycles|          22097.32|23475.590000000004|-5.8710771486467594|\n",
      "|      2003|          6|Motorcycles|           2642.01|          22097.32| -88.04375372217082|\n",
      "|      2003|          7|Motorcycles| 37924.23000000001|           2642.01|  1335.430978686682|\n",
      "|      2003|          8|Motorcycles|44164.909999999996| 37924.23000000001| 16.455653812878953|\n",
      "|      2003|          9|Motorcycles|           3155.58|44164.909999999996| -92.85500638402749|\n",
      "|      2003|         10|Motorcycles| 64235.65000000001|           3155.58| 1935.6210268793695|\n",
      "|      2003|         11|Motorcycles|          109345.5| 64235.65000000001|  70.22556788948191|\n",
      "|      2003|         12|Motorcycles|25431.879999999997|          109345.5| -76.74172233882508|\n",
      "|      2004|          1|Motorcycles|          41200.52|25431.879999999997|  62.00343820433252|\n",
      "|      2004|          2|Motorcycles|           49066.5|          41200.52| 19.091943499742246|\n",
      "|      2004|          4|Motorcycles| 36269.07000000001|           49066.5| -26.08180734309558|\n",
      "|      2004|          5|Motorcycles|46848.950000000004| 36269.07000000001|  29.17053015144859|\n",
      "|      2004|          6|Motorcycles|          47237.41|46848.950000000004| 0.8291754671129217|\n",
      "|      2004|          7|Motorcycles|           22774.0|          47237.41|-51.788211927791984|\n",
      "|      2004|          8|Motorcycles|          62704.93|           22774.0|  175.3356020022833|\n",
      "|      2004|          9|Motorcycles| 42471.04999999999|          62704.93| -32.26840377622623|\n",
      "|      2004|         10|Motorcycles|          39413.96| 42471.04999999999|-7.1980560876173065|\n",
      "+----------+-----------+-----------+------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new1 = Window.partitionBy('PRODUCTLINE').orderBy('ORDER_YEAR', 'ORDER_MONTH')\n",
    "month_sales = month_sales.withColumn('PREV_TOTAL_SALES', lag('TOTAL_SALES').over(new1))\n",
    "month_sales = month_sales.withColumn('PERCENTAGE_GROWTH',\n",
    "    (col('TOTAL_SALES') - col('PREV_TOTAL_SALES')) / col('PREV_TOTAL_SALES') * 100)\n",
    "month_sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7571e0",
   "metadata": {},
   "source": [
    "### u) How can you rebalance the data by portioning based on the COUNTRY column to ensure that large data partitions are avoided?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a7f691b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = sales_df1.repartition(\"COUNTRY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2749b1",
   "metadata": {},
   "source": [
    "Insight : Here, data will be evenly distributed. So large data partitions can be thereby avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2db08",
   "metadata": {},
   "source": [
    "### v) Suppose you have a smaller lookup table with customer details. How would you perform a broadcast join with the large sales_data_sample dataset to improve join performance? What are the key considerations when using broadcast joins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f29cd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = spark.read.csv(\"file:///home/hadoop/Downloads/Customer.csv\", header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "053d5d39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+------------+----+-----------+--------------------+--------------+--------------------+------------+-----------+-------------+----------+-------+---------+---------------+----------------+--------+--------------------+---------+--------------+\n",
      "|ORDERNUMBER|QUANTITYORDERED|PRICEEACH|ORDERLINENUMBER|  SALES|      ORDERDATE| STATUS|QTR_ID|MONTH_ID|YEAR_ID| PRODUCTLINE|MSRP|PRODUCTCODE|        CUSTOMERNAME|         PHONE|        ADDRESSLINE1|ADDRESSLINE2|       CITY|        STATE|POSTALCODE|COUNTRY|TERRITORY|CONTACTLASTNAME|CONTACTFIRSTNAME|DEALSIZE|        CUSTOMERNAME|TERRITORY|         PHONE|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+------------+----+-----------+--------------------+--------------+--------------------+------------+-----------+-------------+----------+-------+---------+---------------+----------------+--------+--------------------+---------+--------------+\n",
      "|      10285|             36|    100.0|              6|4099.68| 8/27/2004 0:00|Shipped|     3|       8|   2004| Motorcycles|  95|   S10_1678|Marta's Replicas Co.|    6175558555| 39323 Spinnaker Dr.|            |  Cambridge|           MA|     51247|    USA|       NA|      Hernandez|           Marta|  Medium|Marta's Replicas Co.|       NA|    6175558555|\n",
      "|      10388|             42|    76.36|              4|3207.12|  3/3/2005 0:00|Shipped|     1|       3|   2005| Motorcycles|  95|   S10_1678|    FunGiftIdeas.com|    5085552555|   1785 First Street|            |New Bedford|           MA|     50553|    USA|       NA|        Benitez|         Violeta|  Medium|    FunGiftIdeas.com|       NA|    5085552555|\n",
      "|      10304|             47|    100.0|              6|10172.7|10/11/2004 0:00|Shipped|     4|      10|   2004|Classic Cars| 214|   S10_1949|  Auto Assoc. & Cie.|    30.59.8555|67, avenue de l'E...|            | Versailles|             |     78000| France|     EMEA|         Tonini|          Daniel|   Large|  Auto Assoc. & Cie.|     EMEA|    30.59.8555|\n",
      "|      10285|             47|    100.0|              9|6484.59| 8/27/2004 0:00|Shipped|     3|       8|   2004| Motorcycles| 118|   S10_2016|Marta's Replicas Co.|    6175558555| 39323 Spinnaker Dr.|            |  Cambridge|           MA|     51247|    USA|       NA|      Hernandez|           Marta|  Medium|Marta's Replicas Co.|       NA|    6175558555|\n",
      "|      10298|             39|    96.34|              1|3757.26| 9/27/2004 0:00|Shipped|     3|       9|   2004| Motorcycles| 118|   S10_2016|   Atelier graphique|    40.32.2555|      54, rue Royale|            |     Nantes|             |     44000| France|     EMEA|        Schmitt|          Carine|  Medium|   Atelier graphique|     EMEA|    40.32.2555|\n",
      "|      10388|             50|    44.51|              5| 2225.5|  3/3/2005 0:00|Shipped|     1|       3|   2005| Motorcycles| 118|   S10_2016|    FunGiftIdeas.com|    5085552555|   1785 First Street|            |New Bedford|           MA|     50553|    USA|       NA|        Benitez|         Violeta|   Small|    FunGiftIdeas.com|       NA|    5085552555|\n",
      "|      10285|             27|    100.0|              8|5438.07| 8/27/2004 0:00|Shipped|     3|       8|   2004| Motorcycles| 193|   S10_4698|Marta's Replicas Co.|    6175558555| 39323 Spinnaker Dr.|            |  Cambridge|           MA|     51247|    USA|       NA|      Hernandez|           Marta|  Medium|Marta's Replicas Co.|       NA|    6175558555|\n",
      "|      10388|             21|    86.77|              7|1822.17|  3/3/2005 0:00|Shipped|     1|       3|   2005| Motorcycles| 193|   S10_4698|    FunGiftIdeas.com|    5085552555|   1785 First Street|            |New Bedford|           MA|     50553|    USA|       NA|        Benitez|         Violeta|   Small|    FunGiftIdeas.com|       NA|    5085552555|\n",
      "|      10273|             30|    100.0|              4| 3508.8| 7/21/2004 0:00|Shipped|     3|       7|   2004|Classic Cars| 136|   S10_4757|          Petit Auto|  (02) 5554 67| Rue Joseph-Bens 532|            |  Bruxelles|             |    B-1180|Belgium|     EMEA|          Dewey|       Catherine|  Medium|          Petit Auto|     EMEA|  (02) 5554 67|\n",
      "|      10316|             33|    100.0|             17|4128.96| 11/1/2004 0:00|Shipped|     4|      11|   2004|Classic Cars| 136|   S10_4757|   giftsbymail.co.uk|(198) 555-8888|Garden House Crow...|            |      Cowes|Isle of Wight|  PO31 7PJ|     UK|     EMEA|        Bennett|           Helen|  Medium|   giftsbymail.co.uk|     EMEA|(198) 555-8888|\n",
      "+-----------+---------------+---------+---------------+-------+---------------+-------+------+--------+-------+------------+----+-----------+--------------------+--------------+--------------------+------------+-----------+-------------+----------+-------+---------+---------------+----------------+--------+--------------------+---------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "broadcast_df = broadcast(customer_df)\n",
    "new2 = sales_df.join(broadcast_df, sales_df1['CUSTOMERNAME'] == broadcast_df['CUSTOMERNAME'])\n",
    "new2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f883a36",
   "metadata": {},
   "source": [
    "Key Considerations:\n",
    "* Ensure that the columnname used for joining both dataframes exists in them.\n",
    "* Ensure the lookup table is small enough for the the main dataset to avoid overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e040d8",
   "metadata": {},
   "source": [
    "### w) Create a UDF that categorizes the sales values (SALES) into custom buckets like Low, Medium, High. Apply this UDF to the DataFrame and calculate the count of orders in each category per COUNTRY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7dca9716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----+\n",
      "|  COUNTRY|SALES_CATEGORY|count|\n",
      "+---------+--------------+-----+\n",
      "|Australia|           Low|   92|\n",
      "|Australia|          High|   56|\n",
      "|Australia|        Medium|   37|\n",
      "|  Austria|           Low|   22|\n",
      "|  Austria|          High|   20|\n",
      "|  Austria|        Medium|   13|\n",
      "|  Belgium|           Low|   18|\n",
      "|  Belgium|          High|   10|\n",
      "|  Belgium|        Medium|    5|\n",
      "|   Canada|           Low|   36|\n",
      "|   Canada|          High|   17|\n",
      "|   Canada|        Medium|   17|\n",
      "|  Denmark|           Low|   26|\n",
      "|  Denmark|          High|   22|\n",
      "|  Denmark|        Medium|   15|\n",
      "|  Finland|           Low|   41|\n",
      "|  Finland|          High|   31|\n",
      "|  Finland|        Medium|   20|\n",
      "|   France|           Low|  144|\n",
      "|   France|          High|   98|\n",
      "+---------+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def salesUdf(sales):\n",
    "    if sales < 3000:\n",
    "        return \"Low\"\n",
    "    elif sales < 4000:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "    \n",
    "sales_udf = udf(salesUdf)\n",
    "sales_df_new = sales_df1.withColumn(\"SALES_CATEGORY\",sales_udf(col(\"SALES\")))\n",
    "sales_df_new.groupBy(\"COUNTRY\", \"SALES_CATEGORY\").count().orderBy(\"COUNTRY\",desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5654a4",
   "metadata": {},
   "source": [
    "### x) Create a Python UDF to calculate discounts for specific product lines. For example, give a 10% discount for Classic Cars and 5% for Motorcycles. Apply this UDF to derive new discounted sales values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "82295447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount(productline, sales):\n",
    "    if productline == 'Classic Cars':\n",
    "        return sales * 0.90 \n",
    "    elif productline == 'Motorcycles':\n",
    "        return sales * 0.95\n",
    "    else:\n",
    "        return sales\n",
    "discount_udf = udf(discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "55198e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------+------------------+\n",
      "|PRODUCTLINE|PRODUCTCODE|  SALES|  DISCOUNTED_SALES|\n",
      "+-----------+-----------+-------+------------------+\n",
      "|Motorcycles|   S10_1678| 2871.0|           2727.45|\n",
      "|Motorcycles|   S10_1678| 2765.9|          2627.605|\n",
      "|Motorcycles|   S10_1678|3884.34|          3690.123|\n",
      "|Motorcycles|   S10_1678| 3746.7|          3559.365|\n",
      "|Motorcycles|   S10_1678|5205.27|         4945.0065|\n",
      "|Motorcycles|   S10_1678|3479.76|          3305.772|\n",
      "|Motorcycles|   S10_1678|2497.77|         2372.8815|\n",
      "|Motorcycles|   S10_1678|5512.32|          5236.704|\n",
      "|Motorcycles|   S10_1678|2168.54|          2060.113|\n",
      "|Motorcycles|   S10_1678|4708.44| 4473.017999999999|\n",
      "|Motorcycles|   S10_1678|3965.66|3767.3769999999995|\n",
      "|Motorcycles|   S10_1678|2333.12|          2216.464|\n",
      "|Motorcycles|   S10_1678|3188.64|3029.2079999999996|\n",
      "|Motorcycles|   S10_1678|3676.76|          3492.922|\n",
      "|Motorcycles|   S10_1678|4177.35|         3968.4825|\n",
      "|Motorcycles|   S10_1678|4099.68|          3894.696|\n",
      "|Motorcycles|   S10_1678|2597.39|2467.5204999999996|\n",
      "|Motorcycles|   S10_1678|4394.38|          4174.661|\n",
      "|Motorcycles|   S10_1678|4358.04|          4140.138|\n",
      "|Motorcycles|   S10_1678|4396.14|4176.3330000000005|\n",
      "+-----------+-----------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "discount_df = sales_df1.withColumn('DISCOUNTED_SALES', discount_udf(col('PRODUCTLINE'), col('SALES')))\n",
    "discount_df.select(\"PRODUCTLINE\",\"PRODUCTCODE\",\"SALES\",\"DISCOUNTED_SALES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52d628",
   "metadata": {},
   "source": [
    "### y) How would you set up an incremental loading mechanism for orders placed daily based on the ORDERDATE column? How can Spark checkpointing can be used with incremental load to ensure no data loss occurs during failures?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147a545",
   "metadata": {},
   "source": [
    "### z) How do you implement a cumulative distribution function (CDF) over the SALES value for each CUSTOMERNAME? What insights can you gather from analyzing the CDF distribution for each customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5a26e520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+\n",
      "|        CUSTOMERNAME|  SALES|                 CDF|\n",
      "+--------------------+-------+--------------------+\n",
      "| Suominen Souveniers| 891.03| 0.03333333333333333|\n",
      "| Suominen Souveniers| 1086.6| 0.06666666666666667|\n",
      "| Suominen Souveniers|1103.76|                 0.1|\n",
      "| Suominen Souveniers|1629.04| 0.13333333333333333|\n",
      "| Suominen Souveniers| 1988.4| 0.16666666666666666|\n",
      "| Suominen Souveniers|2140.11|                 0.2|\n",
      "| Suominen Souveniers|2447.76| 0.23333333333333334|\n",
      "| Suominen Souveniers|2632.89| 0.26666666666666666|\n",
      "| Suominen Souveniers| 2773.8|                 0.3|\n",
      "| Suominen Souveniers|2775.08|  0.3333333333333333|\n",
      "| Suominen Souveniers|2817.87| 0.36666666666666664|\n",
      "| Suominen Souveniers|2851.84|                 0.4|\n",
      "| Suominen Souveniers|2931.98| 0.43333333333333335|\n",
      "| Suominen Souveniers|3128.65|  0.4666666666666667|\n",
      "| Suominen Souveniers|3288.82|                 0.5|\n",
      "| Suominen Souveniers|3595.62|  0.5333333333333333|\n",
      "| Suominen Souveniers|3686.54|  0.5666666666666667|\n",
      "| Suominen Souveniers| 3784.8|                 0.6|\n",
      "| Suominen Souveniers| 4068.7|  0.6333333333333333|\n",
      "| Suominen Souveniers|4142.64|  0.6666666666666666|\n",
      "| Suominen Souveniers|4157.73|                 0.7|\n",
      "| Suominen Souveniers|4381.25|  0.7333333333333333|\n",
      "| Suominen Souveniers| 4836.5|  0.7666666666666667|\n",
      "| Suominen Souveniers|5154.41|                 0.8|\n",
      "| Suominen Souveniers|5500.44|  0.8333333333333334|\n",
      "| Suominen Souveniers|5938.53|  0.8666666666666667|\n",
      "| Suominen Souveniers|6287.66|                 0.9|\n",
      "| Suominen Souveniers| 6576.5|  0.9333333333333333|\n",
      "| Suominen Souveniers| 6756.0|  0.9666666666666667|\n",
      "| Suominen Souveniers|10606.2|                 1.0|\n",
      "|  Amica Models & Co.|  577.6|0.038461538461538464|\n",
      "|  Amica Models & Co.|1381.05| 0.07692307692307693|\n",
      "|  Amica Models & Co.|1557.36| 0.11538461538461539|\n",
      "|  Amica Models & Co.| 1574.0| 0.15384615384615385|\n",
      "|  Amica Models & Co.|1656.69| 0.19230769230769232|\n",
      "|  Amica Models & Co.|1921.92| 0.23076923076923078|\n",
      "|  Amica Models & Co.|2084.81|  0.2692307692307692|\n",
      "|  Amica Models & Co.|2137.05|  0.3076923076923077|\n",
      "|  Amica Models & Co.|2418.24| 0.34615384615384615|\n",
      "|  Amica Models & Co.|2800.08| 0.38461538461538464|\n",
      "|  Amica Models & Co.|2819.28|  0.4230769230769231|\n",
      "|  Amica Models & Co.|2941.89| 0.46153846153846156|\n",
      "|  Amica Models & Co.|2954.53|                 0.5|\n",
      "|  Amica Models & Co.|3006.43|  0.5384615384615384|\n",
      "|  Amica Models & Co.|3474.46|  0.5769230769230769|\n",
      "|  Amica Models & Co.| 3668.6|  0.6153846153846154|\n",
      "|  Amica Models & Co.|3704.05|  0.6538461538461539|\n",
      "|  Amica Models & Co.|4242.24|  0.6923076923076923|\n",
      "|  Amica Models & Co.| 4455.0|  0.7307692307692307|\n",
      "|  Amica Models & Co.| 4750.8|  0.7692307692307693|\n",
      "|  Amica Models & Co.|4946.06|  0.8076923076923077|\n",
      "|  Amica Models & Co.|5126.24|  0.8461538461538461|\n",
      "|  Amica Models & Co.| 5239.5|  0.8846153846153846|\n",
      "|  Amica Models & Co.|8014.82|  0.9230769230769231|\n",
      "|  Amica Models & Co.| 8253.0|  0.9615384615384616|\n",
      "|  Amica Models & Co.|8411.56|                 1.0|\n",
      "|Collectables For ...|1066.75|0.041666666666666664|\n",
      "|Collectables For ...|1237.88| 0.08333333333333333|\n",
      "|Collectables For ...|1340.64|               0.125|\n",
      "|Collectables For ...|1735.92| 0.16666666666666666|\n",
      "+--------------------+-------+--------------------+\n",
      "only showing top 60 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_df = Window.partitionBy('CUSTOMERNAME').orderBy('SALES')\n",
    "ranked_df = sales_df1.withColumn('RANK', row_number().over(window_df))\n",
    "total_sales = sales_df1.groupBy('CUSTOMERNAME').agg(count('SALES').alias('TOTAL_COUNT'))\n",
    "sales_new = ranked_df.join(total_sales, on='CUSTOMERNAME')\n",
    "sales_cdf = sales_new.withColumn('CDF', col('RANK') / col('TOTAL_COUNT'))\n",
    "sales_cdf.select('CUSTOMERNAME', 'SALES', 'CDF').show(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42245c6",
   "metadata": {},
   "source": [
    "Insight - It shows a trend of increasing sales amounts. There is a steady increase in both sales and CDF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99a23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
