{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eeee4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33ca661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f835406fb00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89894839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81470ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a90659",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "047bc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "#setMaster() = Set Spark Content Manager which is local[cpu cores]\n",
    "config = SparkConf().setMaster('local[4]').setAppName(\"ETL Pipeline\")\n",
    "sc = SparkContext(conf = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee20440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ETL Pipeline').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6bfd12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ETL Pipeline</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f83461f4588>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afd69ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ETL Pipeline</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[4] appName=ETL Pipeline>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abc18829",
   "metadata": {},
   "outputs": [],
   "source": [
    "hremployeeDF = spark.read.format(\"jdbc\")\\\n",
    ".option(\"url\", \"jdbc:mysql://localhost:3306/hremployeeDB\")\\\n",
    ".option(\"dbtable\", \"HR_Employee\").option(\"user\",\"root\").option(\"password\", \"hadoop@123\")\\\n",
    ".option(\"driver\", \"com.mysql.cj.jdbc.Driver\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ad88794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+---------+------+---+-------------+-------------+--------------+-----------------+--------------+--------+---------------+----------+------+----------+--------+------+-----------------------+---------------+---------------------+---------------+------------------+\n",
      "|EmployeeID|          Department|             JobRole|Attrition|Gender|Age|MaritalStatus|    Education|EducationField|   BusinessTravel|JobInvolvement|JobLevel|JobSatisfaction|Hourlyrate|Income|Salaryhike|OverTime|Workex|YearsSinceLastPromotion|EmpSatisfaction|TrainingTimesLastYear|WorkLifeBalance|Performance_Rating|\n",
      "+----------+--------------------+--------------------+---------+------+---+-------------+-------------+--------------+-----------------+--------------+--------+---------------+----------+------+----------+--------+------+-----------------------+---------------+---------------------+---------------+------------------+\n",
      "|         1|               Sales|     Sales Executive|      Yes|Female| 41|       Single|      College| Life Sciences|    Travel_Rarely|          High|       2|      Very High|        94|  5993|        11|     Yes|     8|                      0|         Medium|                    0|            Bad|        Excellent\r",
      "|\n",
      "|         2|Research & Develo...|  Research Scientist|       No|  Male| 49|      Married|Below College| Life Sciences|Travel_Frequently|        Medium|       2|         Medium|        61|  5130|        23|      No|    10|                      1|           High|                    3|         Better|      Outstanding\r",
      "|\n",
      "|         3|Research & Develo...|Laboratory Techni...|      Yes|  Male| 37|       Single|      College|         Other|    Travel_Rarely|        Medium|       1|           High|        92|  2090|        15|     Yes|     7|                      0|      Very High|                    3|         Better|        Excellent\r",
      "|\n",
      "|         4|Research & Develo...|  Research Scientist|       No|Female| 33|      Married|       Master| Life Sciences|Travel_Frequently|          High|       1|           High|        56|  2909|        11|     Yes|     8|                      3|      Very High|                    3|         Better|        Excellent\r",
      "|\n",
      "|         5|Research & Develo...|Laboratory Techni...|       No|  Male| 27|      Married|Below College|       Medical|    Travel_Rarely|          High|       1|         Medium|        40|  3468|        12|      No|     6|                      2|            Low|                    3|         Better|        Excellent\r",
      "|\n",
      "+----------+--------------------+--------------------+---------+------+---+-------------+-------------+--------------+-----------------+--------------+--------+---------------+----------+------+----------+--------+------+-----------------------+---------------+---------------------+---------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hremployeeDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a033473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Scan JDBCRelation(HR_Employee) [numPartitions=1] [EmployeeID#0,Department#1,JobRole#2,Attrition#3,Gender#4,Age#5,MaritalStatus#6,Education#7,EducationField#8,BusinessTravel#9,JobInvolvement#10,JobLevel#11,JobSatisfaction#12,Hourlyrate#13,Income#14,Salaryhike#15,OverTime#16,Workex#17,YearsSinceLastPromotion#18,EmpSatisfaction#19,TrainingTimesLastYear#20,WorkLifeBalance#21,Performance_Rating#22] PushedFilters: [], ReadSchema: struct<EmployeeID:int,Department:string,JobRole:string,Attrition:string,Gender:string,Age:int,Mar...\n"
     ]
    }
   ],
   "source": [
    "#Show physical plan of execution which is known as DAG.\n",
    "#How data is scanned from the database\n",
    "hremployeeDF.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaad53d",
   "metadata": {},
   "source": [
    "#### Materialized view of Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ae8483",
   "metadata": {},
   "outputs": [],
   "source": [
    "hremployeeDF.createOrReplaceTempView(\"hremployee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ffaf51",
   "metadata": {},
   "source": [
    "#### 1.Display shape of hremployee tables\n",
    "    * Show number of rows and number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f4bc5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_cols = len(hremployeeDF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24744717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Rows|Columns|\n",
      "+----+-------+\n",
      "|1469|     23|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "SELECT COUNT(*) AS Rows, {num_of_cols} AS Columns FROM hremployee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d7295",
   "metadata": {},
   "source": [
    "spark.sql(\"\"\"select count(*) from information_schema.columns where table_name = 'HR_Employee'\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "494034f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|          EmployeeID|      int|   null|\n",
      "|          Department|   string|   null|\n",
      "|             JobRole|   string|   null|\n",
      "|           Attrition|   string|   null|\n",
      "|              Gender|   string|   null|\n",
      "|                 Age|      int|   null|\n",
      "|       MaritalStatus|   string|   null|\n",
      "|           Education|   string|   null|\n",
      "|      EducationField|   string|   null|\n",
      "|      BusinessTravel|   string|   null|\n",
      "|      JobInvolvement|   string|   null|\n",
      "|            JobLevel|      int|   null|\n",
      "|     JobSatisfaction|   string|   null|\n",
      "|          Hourlyrate|      int|   null|\n",
      "|              Income|      int|   null|\n",
      "|          Salaryhike|      int|   null|\n",
      "|            OverTime|   string|   null|\n",
      "|              Workex|      int|   null|\n",
      "|YearsSinceLastPro...|      int|   null|\n",
      "|     EmpSatisfaction|   string|   null|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('describe hremployee').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f9aa4",
   "metadata": {},
   "source": [
    "#### 2. Write a query to show the first three employee from each Job role to join the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0474105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----+\n",
      "|EmployeeID|             JobRole|rank|\n",
      "+----------+--------------------+----+\n",
      "|         1|     Sales Executive|   1|\n",
      "|        28|     Sales Executive|   2|\n",
      "|        40|     Sales Executive|   3|\n",
      "|         9|Manufacturing Dir...|   1|\n",
      "|        16|Manufacturing Dir...|   2|\n",
      "|        21|Manufacturing Dir...|   3|\n",
      "|         3|Laboratory Techni...|   1|\n",
      "|         5|Laboratory Techni...|   2|\n",
      "|         6|Laboratory Techni...|   3|\n",
      "|        22|Sales Representative|   1|\n",
      "|        34|Sales Representative|   2|\n",
      "|        37|Sales Representative|   3|\n",
      "|        10|Healthcare Repres...|   1|\n",
      "|        29|Healthcare Repres...|   2|\n",
      "|        32|Healthcare Repres...|   3|\n",
      "|         2|  Research Scientist|   1|\n",
      "|         4|  Research Scientist|   2|\n",
      "|        13|  Research Scientist|   3|\n",
      "|        19|             Manager|   1|\n",
      "|        26|             Manager|   2|\n",
      "+----------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select EmployeeID, JobRole, rank from\n",
    "(select EmployeeID, JobRole, row_number() over(partition by JobRole order by EmployeeID asc) as rank\n",
    "from hremployee)  as HRdata where rank <= 3\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccadd42",
   "metadata": {},
   "source": [
    "#### 3. Write a query to show top 3 employee from each job role earning higher salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fcc585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+----+\n",
      "|EmployeeID|             JobRole|Income|rank|\n",
      "+----------+--------------------+------+----+\n",
      "|        99|     Sales Executive| 13872|   1|\n",
      "|       545|     Sales Executive| 13770|   2|\n",
      "|       839|     Sales Executive| 13758|   3|\n",
      "|       722|Manufacturing Dir...| 13973|   1|\n",
      "|       628|Manufacturing Dir...| 13826|   2|\n",
      "|       744|Manufacturing Dir...| 13726|   3|\n",
      "|       678|Laboratory Techni...|  7403|   1|\n",
      "|       817|Laboratory Techni...|  6782|   2|\n",
      "|       945|Laboratory Techni...|  6674|   3|\n",
      "|       565|Sales Representative|  6632|   1|\n",
      "|      1308|Sales Representative|  5405|   2|\n",
      "|      1220|Sales Representative|  4502|   3|\n",
      "|      1181|Healthcare Repres...| 13966|   1|\n",
      "|       317|Healthcare Repres...| 13964|   2|\n",
      "|       190|Healthcare Repres...| 13734|   3|\n",
      "|        68|  Research Scientist|  9724|   1|\n",
      "|      1315|  Research Scientist|  6962|   2|\n",
      "|      1305|  Research Scientist|  6854|   3|\n",
      "|       191|             Manager| 19999|   1|\n",
      "|       852|             Manager| 19943|   2|\n",
      "+----------+--------------------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select EmployeeID, JobRole,Income, rank from\n",
    "(select EmployeeID, JobRole, Income, rank() over(partition by JobRole order by Income desc) as rank\n",
    "from hremployee)  as HRdata where rank <= 3\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b01504",
   "metadata": {},
   "source": [
    "#### 4. Show top 3 highest packages from overall job role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6676dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be70df59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|          jobrole|income|\n",
      "+-----------------+------+\n",
      "|          Manager| 19999|\n",
      "|Research Director| 19973|\n",
      "|          Manager| 19943|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select jobrole, income from hremployee order by income desc limit 3 \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3e93b",
   "metadata": {},
   "source": [
    "#### 5. Write a spark sql query to show employee in order of Ascending order with respect to employee income compared to previous income for each job role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2dfc298",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+-----+-----+\n",
      "|EmployeeID|             JobRole|income| prev| diff|\n",
      "+----------+--------------------+------+-----+-----+\n",
      "|        10|Healthcare Repres...|  5237| null| null|\n",
      "|       285|Healthcare Repres...|  4741|13496|-8755|\n",
      "|      1183|Healthcare Repres...|  6842|13966|-7124|\n",
      "|      1157|Healthcare Repres...|  4148|11245|-7097|\n",
      "|       205|Healthcare Repres...|  6673|13734|-7061|\n",
      "|       677|Healthcare Repres...|  4014|10552|-6538|\n",
      "|       397|Healthcare Repres...|  4522|10965|-6443|\n",
      "|       833|Healthcare Repres...|  5731|12169|-6438|\n",
      "|      1065|Healthcare Repres...|  4035|10466|-6431|\n",
      "|       745|Healthcare Repres...|  4777|10999|-6222|\n",
      "|       736|Healthcare Repres...|  4240|10388|-6148|\n",
      "|      1098|Healthcare Repres...|  4069|10124|-6055|\n",
      "|        89|Healthcare Repres...|  4152|10096|-5944|\n",
      "|       489|Healthcare Repres...|  4089| 9824|-5735|\n",
      "|       929|Healthcare Repres...|  7978|13577|-5599|\n",
      "|       105|Healthcare Repres...|  5163|10673|-5510|\n",
      "|       267|Healthcare Repres...|  5582|10938|-5356|\n",
      "|      1231|Healthcare Repres...|  5562|10748|-5186|\n",
      "|       555|Healthcare Repres...|  6811|11103|-4292|\n",
      "|      1045|Healthcare Repres...|  6651|10851|-4200|\n",
      "+----------+--------------------+------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select EmployeeID, JobRole,income, LAG(income,1) over(order by JobRole) as prev,\n",
    "income - LAG(income,1) over(order by JobRole) as diff\n",
    "from hremployee \n",
    "order by jobrole, diff asc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3852ae4",
   "metadata": {},
   "source": [
    "#### lead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6be28482",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+---+------+------+------+-----------+\n",
      "|employeeid|department|        jobrole|age|gender|income|workex|next_income|\n",
      "+----------+----------+---------------+---+------+------+------+-----------+\n",
      "|         1|     Sales|Sales Executive| 41|Female|  5993|     8|       5376|\n",
      "|        28|     Sales|Sales Executive| 42|  Male|  6825|    10|       8726|\n",
      "|        40|     Sales|Sales Executive| 33|Female|  5376|    10|       4568|\n",
      "|        44|     Sales|Sales Executive| 27|  Male|  8726|     9|       5772|\n",
      "|        47|     Sales|Sales Executive| 34|  Male|  4568|    10|       5454|\n",
      "|        49|     Sales|Sales Executive| 46|  Male|  5772|    14|       4157|\n",
      "|        53|     Sales|Sales Executive| 44|Female|  5454|     9|       9069|\n",
      "|        55|     Sales|Sales Executive| 26|Female|  4157|     5|       7637|\n",
      "|        57|     Sales|Sales Executive| 35|  Male|  9069|     9|       5473|\n",
      "|        64|     Sales|Sales Executive| 59|Female|  7637|    28|       4312|\n",
      "|        71|     Sales|Sales Executive| 59|Female|  5473|    20|      10239|\n",
      "|        77|     Sales|Sales Executive| 35|  Male|  4312|    16|       9619|\n",
      "|        83|     Sales|Sales Executive| 55|  Male| 10239|    24|       5441|\n",
      "|        90|     Sales|Sales Executive| 46|  Male|  9619|     9|       5209|\n",
      "|        92|     Sales|Sales Executive| 51|  Male|  5441|    11|       5010|\n",
      "|        93|     Sales|Sales Executive| 30|Female|  5209|    11|       4999|\n",
      "|        95|     Sales|Sales Executive| 32|  Male|  5010|    12|       4221|\n",
      "|        97|     Sales|Sales Executive| 24|Female|  4999|     4|      13872|\n",
      "|        98|     Sales|Sales Executive| 28|  Male|  4221|     5|       5744|\n",
      "|        99|     Sales|Sales Executive| 58|  Male| 13872|    38|       7428|\n",
      "+----------+----------+---------------+---+------+------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select employeeid,department, jobrole, age, gender, income, workex,\n",
    "lead(income, 2, 0) over(partition by jobrole order by employeeid) as next_income\n",
    "from hremployee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd3329b",
   "metadata": {},
   "source": [
    "#### ntile()\n",
    "     * Dividing records into percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad81cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+---+------+------+------+----------------+\n",
      "|employeeid|          department|             jobrole|age|gender|income|workex|salary_quartiles|\n",
      "+----------+--------------------+--------------------+---+------+------+------+----------------+\n",
      "|       514|Research & Develo...|  Research Scientist| 20|  Male|  1009|     1|               1|\n",
      "|       728|Research & Develo...|  Research Scientist| 18|  Male|  1051|     0|               1|\n",
      "|       765|               Sales|Sales Representative| 28|  Male|  1052|     1|               1|\n",
      "|      1338|               Sales|Sales Representative| 30|  Male|  1081|     1|               1|\n",
      "|      1365|               Sales|Sales Representative| 29|  Male|  1091|     1|               1|\n",
      "|       178|Research & Develo...|Laboratory Techni...| 19|  Male|  1102|     1|               1|\n",
      "|       912|               Sales|Sales Representative| 25|  Male|  1118|     1|               1|\n",
      "|      1402|Research & Develo...|Laboratory Techni...| 31|Female|  1129|     1|               1|\n",
      "|       302|               Sales|Sales Representative| 18|Female|  1200|     0|               1|\n",
      "|       911|Research & Develo...|  Research Scientist| 23|  Male|  1223|     1|               1|\n",
      "|        24|Research & Develo...|  Research Scientist| 21|  Male|  1232|     0|               1|\n",
      "|      1017|Research & Develo...|  Research Scientist| 31|Female|  1261|     1|               1|\n",
      "|      1053|Research & Develo...|  Research Scientist| 30|  Male|  1274|     1|               1|\n",
      "|       516|Research & Develo...|Laboratory Techni...| 35|  Male|  1281|     1|               1|\n",
      "|      1013|               Sales|Sales Representative| 31|Female|  1359|     1|               1|\n",
      "|      1205|Research & Develo...|Laboratory Techni...| 32|  Male|  1393|     1|               1|\n",
      "|       778|Research & Develo...|Laboratory Techni...| 21|Female|  1416|     1|               1|\n",
      "|       297|Research & Develo...|Laboratory Techni...| 18|  Male|  1420|     0|               1|\n",
      "|       150|Research & Develo...|Laboratory Techni...| 19|Female|  1483|     1|               1|\n",
      "|      1311|Research & Develo...|  Research Scientist| 18|Female|  1514|     0|               1|\n",
      "+----------+--------------------+--------------------+---+------+------+------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select employeeid,department, jobrole, age, gender, income, workex,\n",
    "NTILE(4) over(order by income) as salary_quartiles\n",
    "from hremployee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaba421",
   "metadata": {},
   "source": [
    "#### 6. Find the number of EMployee in each percentile group, 0-25th, 25th-50th, 50th-75th,75th-100th using percent_rank and case when ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c37e122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|  rank_cat|count(rank_cat)|\n",
      "+----------+---------------+\n",
      "|    0-25th|            367|\n",
      "| 25th-50th|            366|\n",
      "| 50th-75th|            367|\n",
      "|75th-100th|            369|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "with ranktable as\n",
    "(select employeeid,\n",
    "percent_rank() over(partition by department order by income)\n",
    "as rank from hremployee) \n",
    "\n",
    "select rank_cat, count(rank_cat) from\n",
    "(select employeeid, rank, \n",
    "case\n",
    "    when rank < 0.25 then \"0-25th\"\n",
    "    when rank < 0.50 then \"25th-50th\"\n",
    "    when rank < 0.75 then \"50th-75th\"\n",
    "    else \"75th-100th\"\n",
    "end as rank_cat \n",
    "from ranktable)\n",
    "as rankgrp \n",
    "group by rank_cat \n",
    "order by rank_cat\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c4af3",
   "metadata": {},
   "source": [
    "#### Hive Integration with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae7f26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee9ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3489 SecondaryNameNode\n",
      "2581 NodeManager\n",
      "2389 ResourceManager\n",
      "4645 Jps\n",
      "2885 NameNode\n",
      "3206 DataNode\n",
      "4570 SparkSubmit\n"
     ]
    }
   ],
   "source": [
    "!jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa92e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark integration with Hive warehouse\n",
    "#config name for Hive integration property name 'spark.sql.warehouse.dir'\n",
    "#value = '/user/hive/warehouse'\n",
    "spark = (SparkSession.builder.appName('pyspark-Hive=Integration')\n",
    "        .config('spark.sql.warehouse.dir','/user/hive/warehouse')\n",
    "        .enableHiveSupport().getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c29f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|    airlines|\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0013aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create database if not exists airlines\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d07486b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|    airlines|\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce61bfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "use airlines\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a2d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5ea4728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists flights(DayofMonth int, DayOfWeek int,\n",
    "Carrier varchar(10), OriginAirportID int, DestAirportID int, DepDelay int, ArrDelay int)\n",
    "row format delimited\n",
    "fields terminated by ','\n",
    "lines terminated by '\\n'\n",
    "stored as TEXTFILE\n",
    "TBLPROPERTIES('skip.header.line.count'='1')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adf68474",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|airlines| airports|      false|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "574dfaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"load data local inpath '/home/hadoop/Downloads/flights1.csv'\n",
    "overwrite into table flights\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25a6147c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create table if not exists airports(airport_id int, city varchar(50), state varchar(50), name varchar(50))\n",
    "row format delimited\n",
    "fields terminated by ','\n",
    "lines terminated by '\\n'\n",
    "stored as TEXTFILE\n",
    "TBLPROPERTIES('skip.header.line.count'='1')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fa50aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"load data local inpath '/home/hadoop/Downloads/airports_1.csv'\n",
    "overwrite into table airports\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958dd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44f754bd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9df5549e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0944e6d7",
   "metadata": {},
   "source": [
    "#### 1.Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41490398",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = spark.table('airlines.flights')\n",
    "airports_df = spark.table('airlines.airports')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7802255",
   "metadata": {},
   "source": [
    "#### 2.Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "893bca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join = flights_df.join(airports_df, on = flights_df.OriginAirportID == airports_df.airport_id, how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aea2750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+----------+-----------+-----+--------------------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|airport_id|       city|state|                name|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+----------+-----------+-----+--------------------+\n",
      "|        16|        1|     YV|          11057|        12264|      -6|     -19|     11057|  Charlotte|   NC|Charlotte Douglas...|\n",
      "|        20|        4|     AS|          14747|        14679|      -9|     -12|     14747|    Seattle|   WA|Seattle/Tacoma In...|\n",
      "|        12|        5|     UA|          11618|        15304|      48|      40|     11618|     Newark|   NJ|Newark Liberty In...|\n",
      "|        14|        6|     EV|          14683|        11433|      -8|     -15|     14683|San Antonio|   TX|San Antonio Inter...|\n",
      "|         4|        2|     AA|          14679|        11298|      -6|     -16|     14679|  San Diego|   CA|San Diego Interna...|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+----------+-----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_join.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4a76ed",
   "metadata": {},
   "source": [
    "#### 3.Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73336978",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join=flights_join.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22d73252",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join.write.parquet(\"file:///home/hadoop/Downloads/flights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df1babde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read a parquet file format\n",
    "flights_parquet_df=spark.read.parquet(\"file:///home/hadoop/Downloads/flights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6feee35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join.write.partitionBy(\"Carrier\").parquet(\"/airlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dafa66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_join.write.partitionBy(\"Carrier\").bucketBy(col = 'state', numBuckets = 30)\\\n",
    ".format(\"parquet\").saveAsTable(\"part_bucket_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10058392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|Carrier|count(1)|\n",
      "+-------+--------+\n",
      "|     UA|  287601|\n",
      "|     AA|  291771|\n",
      "|     EV|  158253|\n",
      "|     B6|  122297|\n",
      "|     DL|  385040|\n",
      "|     OO|  161102|\n",
      "|     F9|   35821|\n",
      "|     YV|   53022|\n",
      "|     US|  235031|\n",
      "|     MQ|  113634|\n",
      "|     HA|   18658|\n",
      "|     AS|   69056|\n",
      "|     FL|   93013|\n",
      "|     VX|   34869|\n",
      "|     WN|  580029|\n",
      "|     9E|   80221|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Carrier, count(*) from part_bucket_table group by Carrier\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d74af",
   "metadata": {},
   "source": [
    "#### Load on MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2004d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_properties = {\n",
    "    'user':'root',\n",
    "    'password' : 'hadoop@123',\n",
    "    'driver' : 'com.mysql.cj.jdbc.Driver'\n",
    "}\n",
    "\n",
    "flights_join.write.jdbc(url = \"jdbc:mysql://localhost:3306/flights\", table =\"airlines\", mode = 'overwrite',\n",
    "                       properties=connection_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb342638",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0342a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014dd25c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
